
This repository is a curated collection of **free high-quality resources** on responsible AI topics, including fairness, transparency, interpretability, governance. 

Most resources are from 2020 or later and have been validated as of September 2025.  
They are organized by type (books, frameworks, toolkits, datasets, courses) so you can select the best resources based on your needs.  

---

## 📚 Books (free online)
- **Fairness and Machine Learning: Limitations and Opportunities** (Barocas, Hardt, Narayanan) — [fairmlbook.org](https://fairmlbook.org/) | [PDF](https://fairmlbook.org/pdf/fairmlbook.pdf)  
- **Interpretable Machine Learning** (Christoph Molnar) — [Online Book](https://christophm.github.io/interpretable-ml-book/) (CC BY-NC-SA 4.0 license)
-  **Trustworthy Machine Learning** (Mucsányi, Kirchhof, Nguyen, Rubinstein & Oh)  — [Online Book](https://trustworthyml.io/) (Open access under CC BY 4.0)  
  
---

## ⚖️ Frameworks, Standards & Governance
- **NIST AI Risk Management Framework 1.0 (2023)** — [PDF](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)  
- **NIST Generative AI Profile (2024)**  — [PDF](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf)  
- **EU Artificial Intelligence Act (2024)** — [Official webpage](https://artificialintelligenceact.eu)  
- **International AI Safety Report (2025)**  — [Landing Page](https://www.gov.uk/government/publications/international-ai-safety-report-2025)  
- **Google: End-to-End Responsibility (2024 update)**  — [PDF](https://ai.google/static/documents/ai-responsibility-2024-update.pdf)

---

## 🔍 Practices & Templates 
- **Model Cards for Model Reporting**  — [arXiv PDF](https://arxiv.org/pdf/1810.03993)  
- **Datasheets for Datasets (2021 v8)**  —  [PDF](https://www.microsoft.com/en-us/research/wp-content/uploads/2019/01/1803.09010.pdf)  
- **NIST: Four Principles of Explainable AI (2021)**  —  [PDF](https://nvlpubs.nist.gov/nistpubs/ir/2021/nist.ir.8312.pdf)

---

## 🛠 Toolkits & Libraries
- **Fairlearn** — [Website](https://fairlearn.org/) | [GitHub](https://github.com/fairlearn/fairlearn)  
- **AI Fairness 360 (AIF360)** — [Website](https://ai-fairness-360.org/) | [GitHub](https://github.com/Trusted-AI/AIF360)  
- **Microsoft Responsible AI Toolbox** — [Website](https://responsibleaitoolbox.ai/) | [GitHub](https://github.com/microsoft/responsible-ai-toolbox)  
- **Captum (PyTorch)** — [Website](https://captum.ai/) | [Docs](https://captum.ai/tutorials)

---

## 📊 Datasets & Benchmarks
- **RealToxicityPrompts (2020)**  — [HuggingFace Dataset](https://huggingface.co/datasets/allenai/real-toxicity-prompts)  
- **HolisticBias (2022) & Multilingual HolisticBias (2023)**  — [arXiv](https://arxiv.org/abs/2205.09209) | [EMNLP 2023 PDF](https://aclanthology.org/2023.emnlp-main.874.pdf)

---

## 🎓 Courses & Curated Lists
- **Stanford CS329S: Machine Learning Systems Design**  — [Course Website](https://stanford-cs329s.github.io/)  
- **Trustworthy ML Initiative, Resources**  — [Resource List](https://www.trustworthyml.org/resources)
- **Awesome Machine Learning Interpretability**  — [Git repo](https://github.com/jphall663/awesome-machine-learning-interpretability)

---

## 🌐 Extras
- **Azure ML Fairness Concept Guide**  — [Docs](https://learn.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml)  
- **Google AI Principles & Reports**  — [AI Principles](https://ai.google/principles/)
- **OpenAI System Cards**  — [o1 System Card](https://openai.com/index/openai-o1-system-card/) | [GPT-4o System Card (PDF)](https://cdn.openai.com/gpt-4o-system-card.pdf)
- **Learning from the past to create Responsible AI** — [Github page](https://romanlutz.github.io/ResponsibleAI/)

---

## 🤝 Contributing
This list is a work in progress, and it's meant to be useful for practitioners, researchers, and policymakers interested in building responsible AI. 
Contributions are welcome!  

- If you know of **freely available, reputable resources** that fit the scope, open a PR.  
- Please prefer recent materials and ensure that links are working.  
- Format new entries consistently with the existing structure.  
